{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9a29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing mixture of experts layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddf7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder_layer import DecoderLayer,DecoderLayer_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2465272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export pythonpath to make it work!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc750258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input dimension can be 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc059865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e61db0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt: tensor([[[-0.3517, -0.6832, -1.0543,  1.4223,  0.4189,  0.2320,  0.5124,\n",
      "           1.7014],\n",
      "         [-0.0648, -1.2922, -0.9240, -0.8955,  0.6399, -0.2751,  0.6975,\n",
      "           0.7029],\n",
      "         [-0.4311,  0.2497,  0.6735,  1.0755, -0.1709,  0.0925, -0.5111,\n",
      "          -1.0584],\n",
      "         [-0.9791, -0.8657, -0.9515,  0.9604, -0.4255, -0.3007,  1.2598,\n",
      "          -0.4309]],\n",
      "\n",
      "        [[-0.8677, -0.4915, -0.3486, -0.2433,  0.6749,  0.3176, -1.2774,\n",
      "          -0.5385],\n",
      "         [ 0.2985, -0.1175, -0.6608,  1.8647, -3.4407,  1.9859,  0.1879,\n",
      "          -0.9056],\n",
      "         [-0.1621, -0.4816,  0.1278, -0.2487,  0.3038, -1.0555,  1.3565,\n",
      "          -1.8000],\n",
      "         [-0.6641, -0.6413,  1.8404, -1.8469,  0.1313, -1.7509, -0.1396,\n",
      "          -1.3058]]])\n",
      "tgt_mask: tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "memory: tensor([[[ 0.0526,  0.8739, -0.7208, -1.5964, -0.6504, -0.3283,  0.6652,\n",
      "          -0.5320],\n",
      "         [-0.3661, -2.5825,  0.0792, -0.0296, -0.5748, -1.5106, -1.3222,\n",
      "          -0.3494],\n",
      "         [ 0.4396, -0.1107,  0.0285, -0.2160, -1.9062,  0.8145,  0.8123,\n",
      "           1.7270],\n",
      "         [ 2.0608,  0.4693, -2.1240,  0.4793,  1.6899, -1.7320,  0.0585,\n",
      "           1.0117]],\n",
      "\n",
      "        [[-0.4416, -0.1595, -0.3624,  0.8399, -0.1656,  0.6437,  0.0126,\n",
      "          -0.0503],\n",
      "         [ 2.3066,  1.4225,  0.0787, -2.5321,  0.2123, -0.2850, -0.5443,\n",
      "           0.6866],\n",
      "         [-0.1565,  1.0500, -0.6069,  0.5748, -0.1228,  2.3940, -0.1756,\n",
      "           1.1012],\n",
      "         [ 1.2645, -2.3478,  0.5738,  2.4829,  1.8237, -0.5557, -0.2951,\n",
      "           0.8645]]])\n",
      "memory_mask: tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "cache: tensor([[[ 0.0598, -1.1729, -1.2634,  2.2927,  1.3227, -0.8987, -0.2934,\n",
      "           0.1621],\n",
      "         [-1.7129, -1.0580, -1.2707, -1.4844,  1.2704,  0.2535,  1.1816,\n",
      "           0.5410],\n",
      "         [-0.5416,  0.7082,  0.6735,  0.7400, -0.6631, -1.0798, -0.2595,\n",
      "          -0.6129]],\n",
      "\n",
      "        [[ 1.8096,  0.2381, -0.2718,  0.1149,  0.1016,  1.5388,  1.2642,\n",
      "           1.3058],\n",
      "         [ 0.1195,  0.9975, -0.4667,  2.4440, -0.0508,  1.7401, -0.2054,\n",
      "          -0.3735],\n",
      "         [ 1.9181, -0.8122,  0.2893,  0.8855,  1.1095,  1.0358,  0.3486,\n",
      "           0.6795]]])\n",
      "pre_memory: tensor([[[-0.1267,  1.0185,  1.3182,  0.5423,  1.3330, -1.0853, -0.3874,\n",
      "          -0.2053],\n",
      "         [ 0.3025,  0.5018,  0.1298,  0.5790,  0.0756,  0.0637, -1.0247,\n",
      "           0.8671],\n",
      "         [-0.3519, -0.8897, -0.6619, -0.3445, -0.2172,  0.1880,  0.2226,\n",
      "           0.6530],\n",
      "         [-0.0541, -0.8494, -0.6342,  0.4768, -0.6898,  0.5593,  0.7376,\n",
      "          -0.0155]],\n",
      "\n",
      "        [[-0.0158, -1.3262, -1.1939,  0.9778,  1.3850, -2.1369, -0.6029,\n",
      "           0.4924],\n",
      "         [-2.1786, -0.7492,  0.0641, -0.4674,  0.9204,  0.4434, -1.0280,\n",
      "           0.5334],\n",
      "         [-0.4595,  0.5682,  0.5503,  1.0821,  0.7196, -0.3271, -0.6460,\n",
      "          -1.9516],\n",
      "         [-0.3309,  0.6498, -0.2446, -1.7386, -0.8555,  1.5949, -1.4863,\n",
      "           1.6373]]])\n",
      "pre_memory_mask: tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example values\n",
    "batch_size = 2\n",
    "seq_len_tgt = 4\n",
    "seq_len_mem = 4\n",
    "hidden_size = 8\n",
    "\n",
    "# Random tensor for target input (tgt)\n",
    "tgt = torch.randn(batch_size, seq_len_tgt, hidden_size)\n",
    "print(\"tgt:\", tgt)\n",
    "\n",
    "# Example mask for target input (tgt_mask)\n",
    "tgt_mask = torch.ones(batch_size, seq_len_tgt, dtype=torch.bool)\n",
    "print(\"tgt_mask:\", tgt_mask)\n",
    "\n",
    "# Random tensor for memory (output from the encoder)\n",
    "memory = torch.randn(batch_size, seq_len_mem, hidden_size)\n",
    "print(\"memory:\", memory)\n",
    "\n",
    "# Example mask for memory (memory_mask)\n",
    "memory_mask = torch.ones(batch_size, seq_len_mem, dtype=torch.bool)\n",
    "print(\"memory_mask:\", memory_mask)\n",
    "\n",
    "# Example cache (previous decoder states)\n",
    "cache = torch.randn(batch_size, seq_len_tgt - 1, hidden_size)\n",
    "print(\"cache:\", cache)\n",
    "\n",
    "# Random tensor for pre_memory (if using sequential attention)\n",
    "pre_memory = torch.randn(batch_size, seq_len_mem, hidden_size)\n",
    "print(\"pre_memory:\", pre_memory)\n",
    "\n",
    "# Example mask for pre_memory (pre_memory_mask)\n",
    "pre_memory_mask = torch.ones(batch_size, seq_len_mem, dtype=torch.bool)\n",
    "print(\"pre_memory_mask:\", pre_memory_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f539ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleMultiHeadedAttention(nn.Module):\n",
    "#     def forward(self, query, key, value, mask):\n",
    "#         return query + key + value  # This is just a placeholder\n",
    "\n",
    "# # Instantiate the self-attention and source-attention modules\n",
    "# self_attn = SimpleMultiHeadedAttention()\n",
    "# src_attn = SimpleMultiHeadedAttention()\n",
    "\n",
    "# # Instantiate the DecoderLayer\n",
    "# decoder_layer = DecoderLayer(\n",
    "#     size=hidden_size,\n",
    "#     self_attn=self_attn,\n",
    "#     src_attn=src_attn,\n",
    "#     dropout_rate=0.1,\n",
    "#     normalize_before=True,\n",
    "#     concat_after=False,\n",
    "#     sequential_attn=None\n",
    "# )\n",
    "\n",
    "# # Initialize example inputs\n",
    "# tgt = torch.randn(batch_size, seq_len_tgt, hidden_size)\n",
    "# tgt_mask = torch.ones(batch_size, seq_len_tgt, dtype=torch.bool)\n",
    "# memory = torch.randn(batch_size, seq_len_mem, hidden_size)\n",
    "# memory_mask = torch.ones(batch_size, seq_len_mem, dtype=torch.bool)\n",
    "# cache = torch.randn(batch_size, seq_len_tgt - 1, hidden_size)\n",
    "# pre_memory = torch.randn(batch_size, seq_len_mem, hidden_size)\n",
    "# pre_memory_mask = torch.ones(batch_size, seq_len_mem, dtype=torch.bool)\n",
    "\n",
    "# # Run a forward pass\n",
    "# output = decoder_layer(\n",
    "#     tgt=tgt,\n",
    "#     tgt_mask=tgt_mask,\n",
    "#     memory=memory,\n",
    "#     memory_mask=memory_mask,\n",
    "#     cache=cache,\n",
    "#     pre_memory=pre_memory,\n",
    "#     pre_memory_mask=pre_memory_mask\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8c56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The way to figure this out is to make sure the output of single pointwise ffn is same as output of moe layer. That is it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93f5c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class SMoE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoE, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gate_scores = self.gating_network(x)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "        \n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        expert_outputs = torch.zeros_like(x)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_len):\n",
    "                indices = topk_indices[i, j]\n",
    "                weights = F.softmax(topk_scores[i, j], dim=-1)\n",
    "                output = sum(weights[k] * self.experts[indices[k].item()](x[i:i+1, j:j+1, :]) for k in range(2))\n",
    "                expert_outputs[i:i+1, j:j+1, :] = output\n",
    "        \n",
    "        return expert_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c558b31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.1):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "input_dim = 8\n",
    "hidden_dim = 32\n",
    "\n",
    "# Create an instance of the PointWiseFeedForward network\n",
    "ffn = PointWiseFeedForward(input_dim, hidden_dim)\n",
    "\n",
    "# Example input tensor\n",
    "x = torch.randn(batch_size, seq_len, input_dim)\n",
    "\n",
    "# Forward pass\n",
    "output = ffn(x)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd68c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "sparse_moe = SMoE(input_dim, hidden_dim=hidden_dim,num_experts=8)\n",
    "output = sparse_moe(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05a57a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class SMoE1(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoE1, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gate_scores = self.gating_network(x)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "        print(f\"topk_indices:{topk_indices}\")\n",
    "        topk_experts = [self.experts[idx.item()](x) for idx in topk_indices]\n",
    "        \n",
    "        gate_weights = F.softmax(topk_scores, dim=-1)\n",
    "        output = sum(weight.unsqueeze(-1) * expert_output for weight, expert_output in zip(gate_weights, topk_experts))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2affa78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_moe1 = SMoE1(input_dim, hidden_dim=hidden_dim,num_experts=8)\n",
    "# output = sparse_moe1(x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing faster Feed forward network.\n",
    "\n",
    "#We must have same output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab46431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:6,Seq_len:6,k:2\n",
      "36\n",
      "tensor(894.6484, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Observing load_loss\n",
    "import torch\n",
    "\n",
    "def load_loss(topk_values, topk_indices, num_experts):\n",
    "    \"\"\"\n",
    "    Calculate the load loss based on the distribution of loads among experts.\n",
    "    \n",
    "    Args:\n",
    "        topk_values (torch.Tensor): Tensor containing the top k values after gating. Shape (batch_size, seq_len, k)\n",
    "        topk_indices (torch.Tensor): Tensor containing the indices of the experts corresponding to top k values. Shape (batch_size, seq_len, k)\n",
    "        num_experts (int): The total number of experts.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The calculated load loss.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, k = topk_values.shape\n",
    "    num_elements = batch_size * seq_len  # |X|\n",
    "    print(f\"Batch_size:{batch_size},Seq_len:{seq_len},k:{k}\")\n",
    "    # Initialize the load for each expert\n",
    "    expert_loads = torch.zeros(num_experts, device=topk_values.device)\n",
    "    \n",
    "    # Calculate the load for each expert\n",
    "    for i in range(num_experts):\n",
    "        expert_loads[i] = (topk_indices == i).sum().item()\n",
    "    \n",
    "    # Calculate the logits sum for each expert\n",
    "    logits_sum = torch.zeros(num_experts, device=topk_values.device)\n",
    "    for p in range(num_experts):\n",
    "        mask = topk_indices == p  # Mask to select the logits corresponding to expert p\n",
    "        logits_sum[p] = (topk_values * mask.float()).sum().item()\n",
    "    # Calculate the load loss\n",
    "    load_loss_value = (num_experts / num_elements) * (expert_loads * logits_sum).sum()\n",
    "    \n",
    "    return load_loss_value\n",
    "\n",
    "# Example usage\n",
    "topk_values = torch.tensor([[[3.0781, 3.0156],\n",
    "                             [4.7812, 4.1875],\n",
    "                             [2.2656, 2.0000],\n",
    "                             [3.1562, 1.6641],\n",
    "                             [2.3750, 1.6250],\n",
    "                             [3.9531, 2.4062]],\n",
    "\n",
    "                            [[2.2812, 2.1094],\n",
    "                             [2.5938, 2.4688],\n",
    "                             [3.5625, 1.5234],\n",
    "                             [3.1719, 1.5391],\n",
    "                             [4.2188, 1.1953],\n",
    "                             [4.0625, 1.2031]],\n",
    "\n",
    "                            [[4.5000, 2.5469],\n",
    "                             [1.0625, 0.9609],\n",
    "                             [2.0469, 1.4375],\n",
    "                             [4.3750, 1.0234],\n",
    "                             [4.4375, 1.2656],\n",
    "                             [3.6250, 1.2031]],\n",
    "\n",
    "\n",
    "                            [[4.0312, 3.3125],\n",
    "                             [3.0156, 2.1875],\n",
    "                             [1.3516, 1.2109],\n",
    "                             [4.5312, 4.5000],\n",
    "                             [4.0312, 3.7031],\n",
    "                             [5.0625, 3.6562]],\n",
    "\n",
    "                            [[4.4688, 0.8633],\n",
    "                             [2.4844, 1.5625],\n",
    "                             [2.1875, 1.8984],\n",
    "                             [4.8438, 0.8516],\n",
    "                             [4.3438, 0.8398],\n",
    "                             [4.1250, 0.9844]],\n",
    "\n",
    "                            [[3.4062, 2.0625],\n",
    "                             [2.5156, 1.3203],\n",
    "                             [1.2656, 1.2500],\n",
    "                             [3.5625, 3.1094],\n",
    "                             [3.6875, 3.4062],\n",
    "                             [3.8281, 3.3438]]], device='cuda:0', dtype=torch.bfloat16)\n",
    "\n",
    "topk_indices = torch.tensor([[[5, 7],\n",
    "                              [2, 1],\n",
    "                              [0, 1],\n",
    "                              [0, 1],\n",
    "                              [3, 5],\n",
    "                              [5, 7]],\n",
    "\n",
    "                             [[2, 5],\n",
    "                              [5, 3],\n",
    "                              [7, 3],\n",
    "                              [5, 1],\n",
    "                              [5, 3],\n",
    "                              [5, 1]],\n",
    "\n",
    "                             [[1, 5],\n",
    "                              [2, 1],\n",
    "                              [7, 2],\n",
    "                              [5, 1],\n",
    "                              [5, 1],\n",
    "                              [5, 3]],\n",
    "\n",
    "                             [[5, 1],\n",
    "                              [5, 7],\n",
    "                              [3, 5],\n",
    "                              [1, 5],\n",
    "                              [1, 5],\n",
    "                              [1, 5]],\n",
    "\n",
    "                             [[5, 3],\n",
    "                              [7, 5],\n",
    "                              [0, 1],\n",
    "                              [5, 7],\n",
    "                              [5, 7],\n",
    "                              [5, 7]],\n",
    "\n",
    "                             [[1, 5],\n",
    "                              [5, 3],\n",
    "                              [0, 5],\n",
    "                              [5, 1],\n",
    "                              [1, 5],\n",
    "                              [1, 5]]], device='cuda:0')\n",
    "\n",
    "num_experts = 8\n",
    "loss = load_loss(topk_values, topk_indices, num_experts)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03362569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, ModuleList\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from beartype import beartype\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Tuple, Union\n",
    "from einops import rearrange, repeat, reduce, pack, unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba21ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Okay let's try out st-moe implementation. They used einstein notation. This is important to learn right now.\n",
    "class TopNGating(Module):\n",
    "\n",
    "    @beartype\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_gates,\n",
    "        eps = 1e-9,\n",
    "        top_n = 2,\n",
    "        threshold_train: Union[float, Tuple[float, ...]] = 0.2,\n",
    "        threshold_eval: Union[float, Tuple[float, ...]] = 0.2,\n",
    "        capacity_factor_train = 1.25,\n",
    "        capacity_factor_eval = 2.,\n",
    "        straight_through_dispatch_tensor = True,\n",
    "        differentiable_topk = False,\n",
    "        differentiable_topk_fused = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.num_gates = num_gates\n",
    "        self.to_gates = nn.Linear(dim, num_gates, bias = False)\n",
    "\n",
    "        self.differentiable_topk = differentiable_topk\n",
    "\n",
    "        self.topk = partial(\n",
    "            maybe_differentiable_topk,\n",
    "            non_differentiable = not differentiable_topk,\n",
    "            fused = differentiable_topk_fused # use triton fused coordinate descent if possible by default\n",
    "        )\n",
    "\n",
    "        assert top_n >= 2, 'must be 2 or more experts'\n",
    "        self.top_n = top_n\n",
    "        top_n_minus_1 = top_n - 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        noise_gates = False,\n",
    "        noise_mult = 1.\n",
    "    ):\n",
    "        \"\"\"\n",
    "        einstein notation:\n",
    "\n",
    "        b - batch\n",
    "        n - sequence\n",
    "        e - experts\n",
    "        k - top-n experts\n",
    "        \"\"\"\n",
    "\n",
    "        *_, b, group_size, dim, dtype, top_n, num_gates, eps = *x.shape, x.dtype, self.top_n, self.num_gates, self.eps\n",
    "\n",
    "        # threshold, capacity depending on training or eval\n",
    "\n",
    "        suffix = 'train' if self.training else 'eval'\n",
    "\n",
    "        threshold = getattr(self, f'threshold_{suffix}')\n",
    "        capacity_factor = getattr(self, f'capacity_factor_{suffix}')\n",
    "\n",
    "        # Each sequence sends (at most?) expert_capacity positions to each expert.\n",
    "        # Static expert_capacity dimension is needed for expert batch sizes\n",
    "\n",
    "        expert_capacity = min(group_size, int((group_size * capacity_factor) / num_gates))\n",
    "        expert_capacity = max(expert_capacity, MIN_EXPERT_CAPACITY)\n",
    "        expert_capacity_f = float(expert_capacity)\n",
    "\n",
    "        # gate logits and gates\n",
    "\n",
    "        gate_logits = self.to_gates(x)\n",
    "\n",
    "        maybe_noised_gate_logits = gate_logits\n",
    "\n",
    "        if noise_gates:\n",
    "            noise = gumbel_noise(maybe_noised_gate_logits)\n",
    "            maybe_noised_gate_logits = maybe_noised_gate_logits + noise * noise_mult\n",
    "\n",
    "        raw_gates = maybe_noised_gate_logits.softmax(dim = -1)\n",
    "\n",
    "        # find top N experts per position\n",
    "\n",
    "        topk_return = self.topk(raw_gates, k = top_n)\n",
    "\n",
    "        gate_indices = topk_return.indices\n",
    "\n",
    "        if self.differentiable_topk:\n",
    "            # allow for differentiable topk using coordinate descent\n",
    "            # used successfully for routing from CoLT5 paper https://github.com/lucidrains/CoLT5-attention\n",
    "\n",
    "            gates = topk_return.coor_descent_values\n",
    "        else:\n",
    "            gates = topk_return.values\n",
    "\n",
    "        # move the top-n dimension to be first\n",
    "\n",
    "        gates = rearrange(gates, '... k -> k ...')\n",
    "        gate_indices = rearrange(gate_indices, '... k -> k ...')\n",
    "\n",
    "        # masks\n",
    "\n",
    "        one_hot_gate_indices = F.one_hot(gate_indices, num_gates)\n",
    "        mask = one_hot_gate_indices.float()\n",
    "\n",
    "        mask_1 = mask[0] # needed for balancing loss\n",
    "\n",
    "        # normalize top-n gate scores\n",
    "\n",
    "        denom = reduce(gates, 'k ... -> 1 ...', 'sum').clamp(min = eps)\n",
    "        gates = gates / denom\n",
    "\n",
    "        # best performing policy was to route to the second expert, with probability of min(1., score / threshold), where score = gate2 / (gate1 + gate2)\n",
    "        # optimal threshold was ~ 0.2\n",
    "        # generalized to more than 2 experts\n",
    "\n",
    "        probs = torch.zeros_like(gates).uniform_(0., 1.)\n",
    "\n",
    "        threshold = rearrange(threshold, 'k -> k 1 1')\n",
    "        should_route = probs < (gates / threshold.clamp(min = eps))\n",
    "\n",
    "        # tokens should always be routed to first expert\n",
    "        # threshold for first expert already set to very small number, but just in case\n",
    "\n",
    "        should_route[0, ...] = True\n",
    "\n",
    "        mask *= rearrange(should_route.float(), '... -> ... 1')\n",
    "\n",
    "        mask_cumsum = cumsum_exclusive(mask, dim = -2) # along sequence dimension\n",
    "\n",
    "        # compute assignment to experts - (batch, seq, experts)\n",
    "\n",
    "        # This is the position within the expert's mini-batch for this sequence\n",
    "\n",
    "        positions = []\n",
    "        prev_expert_count = 0.\n",
    "\n",
    "        for n in range(self.top_n):\n",
    "            position_in_expert = (mask_cumsum[n] + prev_expert_count) * mask[n]\n",
    "\n",
    "            # Remove the elements that don't fit. (batch, sequence, experts)\n",
    "            mask[n] *= (position_in_expert < expert_capacity_f).float()\n",
    "\n",
    "            # How many examples in this sequence go to this expert - needed for the next iteration as offset\n",
    "            prev_expert_count = reduce(mask[n], '... n e -> ... 1 e', 'sum')\n",
    "\n",
    "            # (batch, sequence)\n",
    "            position_in_expert = reduce(position_in_expert, '... n e -> ... n', 'sum')\n",
    "            positions.append(position_in_expert)\n",
    "\n",
    "        positions = torch.stack(positions)\n",
    "\n",
    "        # (k, batch, sequence) - mostly ones, but zeros where something didn't fit\n",
    "        mask_flat = reduce(mask, '... n e -> ... n', 'sum')\n",
    "\n",
    "        # (k, batch, sequence) - weighted assignment\n",
    "        # following https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/moe.py#L1903\n",
    "        gates = gates * mask_flat\n",
    "\n",
    "        # (batch, sequence, experts, expert_capacity)\n",
    "\n",
    "        N = None\n",
    "\n",
    "        gates = gates[..., N, N]\n",
    "        mask_flat = mask_flat[..., N, N]\n",
    "        one_hot_gate_indices = one_hot_gate_indices[..., N]\n",
    "        safe_one_hot_gates = safe_one_hot(positions.long(), expert_capacity)[..., N, :]\n",
    "\n",
    "        combine_tensor = reduce(\n",
    "            gates\n",
    "            * mask_flat\n",
    "            * one_hot_gate_indices\n",
    "            * safe_one_hot_gates\n",
    "        , 'k ... -> ...', 'sum')\n",
    "\n",
    "        # dispatch tensor\n",
    "\n",
    "        dispatch_tensor = combine_tensor.bool().type(dtype)\n",
    "\n",
    "        if self.straight_through_dispatch_tensor:\n",
    "            dispatch_tensor = dispatch_tensor + combine_tensor - combine_tensor.detach()\n",
    "\n",
    "        # balance losses - (batch, experts)\n",
    "        # We want to equalize the fraction of the batch assigned to each expert\n",
    "\n",
    "        if self.training:\n",
    "            density_1 = reduce(mask_1, '... n e -> ... e', 'mean')\n",
    "            density_1_proxy = reduce(raw_gates, '... n e -> ... e', 'mean') # Something continuous that is correlated with what we want to equalize.\n",
    "\n",
    "            balance_loss = (density_1_proxy * density_1).mean() * float(num_gates ** 2)\n",
    "        else:\n",
    "            balance_loss = self.zero\n",
    "\n",
    "        # calculate the router z-loss proposed in paper\n",
    "\n",
    "        if self.training:\n",
    "            router_z_loss = torch.logsumexp(gate_logits, dim = -1)\n",
    "            router_z_loss = torch.square(router_z_loss)            \n",
    "            router_z_loss = router_z_loss.mean()\n",
    "        else:\n",
    "            router_z_loss = self.zero\n",
    "\n",
    "        return dispatch_tensor, combine_tensor, balance_loss, router_z_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5de3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoE(Module):\n",
    "\n",
    "    @beartype\n",
    "    def __init__(self,\n",
    "        dim,\n",
    "        num_experts = 16,\n",
    "        expert_hidden_mult = 4,\n",
    "        threshold_train = 0.2,\n",
    "        threshold_eval = 0.2,\n",
    "        capacity_factor_train = 1.25,\n",
    "        capacity_factor_eval = 2.,\n",
    "        gating_top_n = 2,\n",
    "        balance_loss_coef = 1e-2,\n",
    "        router_z_loss_coef = 1e-3,\n",
    "        experts: Optional[Module] = None,\n",
    "        straight_through_dispatch_tensor = True,\n",
    "        differentiable_topk = False,\n",
    "        differentiable_topk_fused = True,\n",
    "        is_distributed = None,\n",
    "        allow_var_seq_len = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        self.gate = TopNGating(\n",
    "            dim,\n",
    "            top_n = gating_top_n,\n",
    "            num_gates = num_experts,\n",
    "            straight_through_dispatch_tensor = straight_through_dispatch_tensor,\n",
    "            differentiable_topk = differentiable_topk,\n",
    "            threshold_train = threshold_train,\n",
    "            threshold_eval = threshold_eval,\n",
    "            capacity_factor_train = capacity_factor_train,\n",
    "            capacity_factor_eval = capacity_factor_eval\n",
    "        )\n",
    "\n",
    "        experts = default(experts, lambda: [Expert(dim = dim, hidden_mult = expert_hidden_mult) for _ in range(num_experts)])\n",
    "\n",
    "        self.experts = Experts(\n",
    "            experts,\n",
    "            is_distributed = is_distributed,\n",
    "            allow_var_seq_len = allow_var_seq_len\n",
    "        )\n",
    "\n",
    "        self.balance_loss_coef = balance_loss_coef\n",
    "        self.router_z_loss_coef = router_z_loss_coef\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        noise_gates = False,\n",
    "        noise_mult = 1.\n",
    "    ):\n",
    "        dispatch_tensor, combine_tensor, balance_loss, router_z_loss = self.gate(x, noise_gates = noise_gates, noise_mult = noise_mult)\n",
    "\n",
    "        # dispatch\n",
    "\n",
    "        expert_inputs = einsum('b n d, b n e c -> b e c d', x, dispatch_tensor)\n",
    "\n",
    "        # feed the expert inputs through the experts.\n",
    "\n",
    "        expert_outputs = self.experts(expert_inputs)\n",
    "\n",
    "        # combine\n",
    "\n",
    "        output = einsum('b e c d, b n e c -> b n d', expert_outputs, combine_tensor)\n",
    "\n",
    "        # losses\n",
    "\n",
    "        weighted_balance_loss = balance_loss * self.balance_loss_coef\n",
    "        weighted_router_z_loss = router_z_loss * self.router_z_loss_coef\n",
    "\n",
    "        # combine the losses\n",
    "\n",
    "        total_aux_loss = weighted_balance_loss + weighted_router_z_loss\n",
    "\n",
    "        return MixtureOfExpertsReturn(output, total_aux_loss, balance_loss, router_z_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e009fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install beartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c72f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maybe_differentiable_topk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      4\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m----> 5\u001b[0m moe \u001b[38;5;241m=\u001b[39m \u001b[43mMoE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Example input tensor\u001b[39;00m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, seq_len, input_dim)\n",
      "File \u001b[0;32m<@beartype(__main__.MoE.__init__) at 0x7f481da87010>:35\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(__beartype_object_139947712097088, __beartype_get_violation, __beartype_conf, __beartype_func, *args, **kwargs)\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mMoE.__init__\u001b[0;34m(self, dim, num_experts, expert_hidden_mult, threshold_train, threshold_eval, capacity_factor_train, capacity_factor_eval, gating_top_n, balance_loss_coef, router_z_loss_coef, experts, straight_through_dispatch_tensor, differentiable_topk, differentiable_topk_fused, is_distributed, allow_var_seq_len)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_experts \u001b[38;5;241m=\u001b[39m num_experts\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate \u001b[38;5;241m=\u001b[39m \u001b[43mTopNGating\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgating_top_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_experts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstraight_through_dispatch_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstraight_through_dispatch_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable_topk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdifferentiable_topk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapacity_factor_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcapacity_factor_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapacity_factor_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcapacity_factor_eval\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m experts \u001b[38;5;241m=\u001b[39m default(experts, \u001b[38;5;28;01mlambda\u001b[39;00m: [Expert(dim \u001b[38;5;241m=\u001b[39m dim, hidden_mult \u001b[38;5;241m=\u001b[39m expert_hidden_mult) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_experts)])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts \u001b[38;5;241m=\u001b[39m Experts(\n\u001b[1;32m     41\u001b[0m     experts,\n\u001b[1;32m     42\u001b[0m     is_distributed \u001b[38;5;241m=\u001b[39m is_distributed,\n\u001b[1;32m     43\u001b[0m     allow_var_seq_len \u001b[38;5;241m=\u001b[39m allow_var_seq_len\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m<@beartype(__main__.TopNGating.__init__) at 0x7f481da86b90>:76\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(__beartype_getrandbits, __beartype_get_violation, __beartype_conf, __beartype_func, *args, **kwargs)\u001b[0m\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mTopNGating.__init__\u001b[0;34m(self, dim, num_gates, eps, top_n, threshold_train, threshold_eval, capacity_factor_train, capacity_factor_eval, straight_through_dispatch_tensor, differentiable_topk, differentiable_topk_fused)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_gates \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(dim, num_gates, bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiable_topk \u001b[38;5;241m=\u001b[39m differentiable_topk\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk \u001b[38;5;241m=\u001b[39m partial(\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mmaybe_differentiable_topk\u001b[49m,\n\u001b[1;32m     28\u001b[0m     non_differentiable \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m differentiable_topk,\n\u001b[1;32m     29\u001b[0m     fused \u001b[38;5;241m=\u001b[39m differentiable_topk_fused \u001b[38;5;66;03m# use triton fused coordinate descent if possible by default\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m top_n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust be 2 or more experts\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_n \u001b[38;5;241m=\u001b[39m top_n\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maybe_differentiable_topk' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "input_dim = 8\n",
    "hidden_dim = 32\n",
    "moe = MoE(dim=input_dim)\n",
    "\n",
    "# Example input tensor\n",
    "x = torch.randn(batch_size, seq_len, input_dim)\n",
    "moe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0c689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs differ between the methods.\n",
      "Output new method:\n",
      "tensor([[[-0.1067,  0.1846,  0.1662,  ...,  0.2042, -0.0200,  0.0493],\n",
      "         [ 0.1352, -0.1574,  0.0419,  ..., -0.0442, -0.2453, -0.0428],\n",
      "         [-0.1433, -0.1742,  0.0132,  ...,  0.4329, -0.1987, -0.0466],\n",
      "         ...,\n",
      "         [-0.1376, -0.0190,  0.2820,  ..., -0.2507, -0.2436,  0.4125],\n",
      "         [ 0.3310,  0.0279,  0.3362,  ..., -0.0032,  0.0343,  0.1015],\n",
      "         [ 0.1277,  0.0539,  0.1638,  ...,  0.1252, -0.1743,  0.0314]],\n",
      "\n",
      "        [[-0.1142,  0.3524,  0.2288,  ..., -0.0909, -0.0117,  0.1134],\n",
      "         [ 0.2779,  0.0531, -0.1934,  ..., -0.0592,  0.2043,  0.0534],\n",
      "         [ 0.2327,  0.1313,  0.3657,  ..., -0.1027, -0.1279,  0.0819],\n",
      "         ...,\n",
      "         [ 0.0541, -0.1235, -0.0201,  ..., -0.0332,  0.1641,  0.1118],\n",
      "         [-0.0047,  0.3385, -0.5139,  ..., -0.0325, -0.0577,  0.0386],\n",
      "         [-0.0379, -0.2084, -0.2119,  ..., -0.1217,  0.0397,  0.0066]],\n",
      "\n",
      "        [[ 0.0481,  0.1464,  0.1431,  ...,  0.1191,  0.2358,  0.0411],\n",
      "         [ 0.0429, -0.0020,  0.2478,  ..., -0.0456,  0.3817,  0.0856],\n",
      "         [ 0.0361,  0.1983,  0.0213,  ...,  0.1136,  0.0437,  0.0103],\n",
      "         ...,\n",
      "         [ 0.1048, -0.0920,  0.0168,  ...,  0.1194, -0.3481,  0.0740],\n",
      "         [-0.3195,  0.1891,  0.1039,  ..., -0.3532, -0.0586, -0.2055],\n",
      "         [ 0.2656,  0.0196, -0.1103,  ...,  0.0139, -0.0593,  0.0087]],\n",
      "\n",
      "        [[-0.2424, -0.3808,  0.0349,  ..., -0.2589,  0.1258, -0.1549],\n",
      "         [ 0.1708, -0.0617,  0.0961,  ...,  0.0828,  0.2808,  0.1948],\n",
      "         [ 0.1685,  0.1517, -0.4197,  ..., -0.2677,  0.1266, -0.2051],\n",
      "         ...,\n",
      "         [ 0.0765,  0.2188, -0.1451,  ..., -0.0471, -0.1266, -0.1879],\n",
      "         [ 0.0771, -0.0315, -0.3125,  ...,  0.1821,  0.1321, -0.0783],\n",
      "         [ 0.0904, -0.2567, -0.2299,  ..., -0.5116,  0.0991,  0.2832]]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "Output original method:\n",
      "tensor([[[ 1.3082e-01,  1.6563e-01,  4.1653e-02,  ..., -2.2603e-01,\n",
      "          -7.3465e-02,  7.8630e-02],\n",
      "         [-1.3417e-01, -1.0778e-01, -1.8121e-02,  ..., -2.3720e-01,\n",
      "           6.4090e-02,  6.7970e-02],\n",
      "         [-1.5226e-01,  1.8696e-01, -8.2782e-02,  ...,  3.3045e-02,\n",
      "          -3.3825e-02,  7.5411e-02],\n",
      "         ...,\n",
      "         [ 2.0526e-01, -1.0766e-01,  1.1490e-01,  ..., -1.6139e-01,\n",
      "           1.9672e-01, -8.9715e-02],\n",
      "         [ 1.3444e-01, -1.1484e-01, -2.8529e-01,  ...,  4.9698e-02,\n",
      "           9.4008e-02,  2.1113e-01],\n",
      "         [-7.7669e-02,  5.6433e-03, -1.7898e-01,  ..., -7.0148e-02,\n",
      "           4.0989e-02, -2.4595e-01]],\n",
      "\n",
      "        [[-2.2096e-01,  1.5502e-01, -7.7533e-03,  ..., -1.0507e-01,\n",
      "           1.8487e-01, -1.7801e-01],\n",
      "         [-1.6388e-01, -2.0103e-01,  6.7127e-02,  ...,  2.8505e-02,\n",
      "          -3.3133e-01,  2.1417e-02],\n",
      "         [-4.4284e-01,  3.0237e-01,  1.4740e-01,  ...,  4.8788e-02,\n",
      "          -1.5588e-01,  3.9302e-01],\n",
      "         ...,\n",
      "         [-1.5761e-01,  2.4891e-01, -1.5799e-01,  ...,  7.6650e-02,\n",
      "          -3.9833e-01, -1.7371e-01],\n",
      "         [ 6.2172e-02, -3.9801e-02,  4.4738e-02,  ...,  1.6706e-02,\n",
      "          -3.9300e-01,  1.5341e-01],\n",
      "         [ 2.4012e-01,  4.6382e-01, -4.6103e-02,  ...,  1.3832e-01,\n",
      "          -1.3315e-01, -2.2044e-01]],\n",
      "\n",
      "        [[-5.5443e-02, -3.0804e-02,  2.1045e-02,  ..., -3.0459e-01,\n",
      "           1.8680e-01,  9.7737e-02],\n",
      "         [ 2.4402e-01,  2.9861e-01, -4.3307e-02,  ...,  2.1187e-01,\n",
      "          -3.5560e-01,  3.0057e-02],\n",
      "         [ 1.5789e-01,  2.0096e-01, -1.3483e-01,  ..., -5.2093e-02,\n",
      "          -6.9464e-03, -8.9531e-02],\n",
      "         ...,\n",
      "         [-1.5437e-01,  3.3379e-01,  1.2433e-01,  ...,  2.4898e-02,\n",
      "          -5.9376e-03, -1.3339e-02],\n",
      "         [ 5.3858e-02,  3.3692e-01, -6.7198e-03,  ..., -1.6767e-01,\n",
      "           1.2856e-01,  9.7554e-03],\n",
      "         [ 1.7491e-01,  3.8467e-01,  7.4633e-02,  ..., -2.8190e-02,\n",
      "           6.8536e-02,  1.6387e-01]],\n",
      "\n",
      "        [[-4.5334e-01,  3.9357e-01, -2.4826e-01,  ..., -7.8468e-02,\n",
      "           1.9948e-01,  1.1272e-01],\n",
      "         [ 3.3446e-01,  4.7922e-05,  2.7089e-02,  ..., -2.6876e-01,\n",
      "           2.1251e-02,  2.9471e-01],\n",
      "         [ 1.8585e-01, -3.4736e-02, -4.8967e-02,  ..., -7.8985e-02,\n",
      "           2.1420e-02, -1.1045e-01],\n",
      "         ...,\n",
      "         [ 1.8069e-03,  1.6909e-01, -2.0712e-01,  ..., -1.2648e-01,\n",
      "          -2.9164e-02, -1.9992e-01],\n",
      "         [ 8.6461e-02,  1.4734e-01, -8.2163e-02,  ...,  1.1373e-01,\n",
      "          -5.5620e-02, -1.3148e-01],\n",
      "         [ 4.5301e-01,  1.0044e-01, -1.1060e-01,  ..., -1.5038e-02,\n",
      "          -6.5686e-02,  8.3277e-02]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import os\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class SMoE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoE, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        gate_scores = self.gating_network(x)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Compute expert outputs for all experts in parallel\n",
    "        all_expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=2)  # (batch_size, seq_len, num_experts, input_dim)\n",
    "        \n",
    "        # Select top-k expert outputs\n",
    "        selected_expert_outputs = all_expert_outputs.gather(2, topk_indices.unsqueeze(-1).expand(-1, -1, -1, x.size(-1)))  # (batch_size, seq_len, 2, input_dim)\n",
    "        \n",
    "        # Calculate weights and apply them\n",
    "        weights = F.softmax(topk_scores, dim=-1).unsqueeze(-1)  # (batch_size, seq_len, 2, 1)\n",
    "        expert_outputs = (selected_expert_outputs * weights).sum(dim=2)  # (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        return expert_outputs, (topk_scores, topk_indices, gate_scores)\n",
    "\n",
    "class SMoEOriginal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoEOriginal, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        gate_scores = self.gating_network(x)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        expert_outputs = torch.zeros_like(x).to(device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_len):\n",
    "                indices = topk_indices[i, j]\n",
    "                weights = F.softmax(topk_scores[i, j], dim=-1)\n",
    "                output = sum(weights[k] * self.experts[indices[k].item()](x[i:i+1, j:j+1, :]) for k in range(2))\n",
    "                expert_outputs[i:i+1, j:j+1, :] = output\n",
    "        \n",
    "        return expert_outputs, (topk_scores, topk_indices, gate_scores)\n",
    "\n",
    "def test_models():\n",
    "    input_dim = 128\n",
    "    hidden_dim = 256\n",
    "    num_experts = 8\n",
    "    batch_size = 4\n",
    "    seq_len = 10\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    x = torch.randn(batch_size, seq_len, input_dim)\n",
    "\n",
    "    model_new = SMoE(input_dim, hidden_dim, num_experts)\n",
    "    model_original = SMoEOriginal(input_dim, hidden_dim, num_experts)\n",
    "\n",
    "    output_new, _ = model_new(x)\n",
    "    output_original, _ = model_original(x)\n",
    "\n",
    "    # Check if the outputs are close\n",
    "    if torch.allclose(output_new, output_original, atol=1e-6):\n",
    "        print(\"The outputs are the same for both methods.\")\n",
    "    else:\n",
    "        print(\"The outputs differ between the methods.\")\n",
    "\n",
    "    print(\"Output new method:\")\n",
    "    print(output_new)\n",
    "    print(\"Output original method:\")\n",
    "    print(output_original)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13b3e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs are the same for both methods.\n",
      "Output new method:\n",
      "tensor([[[ 1.3082e-01,  1.6563e-01,  4.1653e-02,  ..., -2.2603e-01,\n",
      "          -7.3465e-02,  7.8630e-02],\n",
      "         [-1.3417e-01, -1.0778e-01, -1.8121e-02,  ..., -2.3720e-01,\n",
      "           6.4090e-02,  6.7970e-02],\n",
      "         [-1.5226e-01,  1.8696e-01, -8.2782e-02,  ...,  3.3045e-02,\n",
      "          -3.3825e-02,  7.5411e-02],\n",
      "         ...,\n",
      "         [ 2.0526e-01, -1.0766e-01,  1.1490e-01,  ..., -1.6139e-01,\n",
      "           1.9672e-01, -8.9715e-02],\n",
      "         [ 1.3444e-01, -1.1484e-01, -2.8529e-01,  ...,  4.9697e-02,\n",
      "           9.4008e-02,  2.1113e-01],\n",
      "         [-7.7669e-02,  5.6432e-03, -1.7898e-01,  ..., -7.0148e-02,\n",
      "           4.0989e-02, -2.4595e-01]],\n",
      "\n",
      "        [[-2.2096e-01,  1.5502e-01, -7.7533e-03,  ..., -1.0507e-01,\n",
      "           1.8487e-01, -1.7801e-01],\n",
      "         [-1.6388e-01, -2.0103e-01,  6.7127e-02,  ...,  2.8505e-02,\n",
      "          -3.3133e-01,  2.1417e-02],\n",
      "         [-4.4284e-01,  3.0237e-01,  1.4740e-01,  ...,  4.8788e-02,\n",
      "          -1.5588e-01,  3.9302e-01],\n",
      "         ...,\n",
      "         [-1.5761e-01,  2.4891e-01, -1.5799e-01,  ...,  7.6650e-02,\n",
      "          -3.9833e-01, -1.7371e-01],\n",
      "         [ 6.2172e-02, -3.9801e-02,  4.4738e-02,  ...,  1.6706e-02,\n",
      "          -3.9300e-01,  1.5341e-01],\n",
      "         [ 2.4012e-01,  4.6382e-01, -4.6103e-02,  ...,  1.3832e-01,\n",
      "          -1.3315e-01, -2.2044e-01]],\n",
      "\n",
      "        [[-5.5443e-02, -3.0804e-02,  2.1045e-02,  ..., -3.0459e-01,\n",
      "           1.8680e-01,  9.7737e-02],\n",
      "         [ 2.4402e-01,  2.9861e-01, -4.3307e-02,  ...,  2.1187e-01,\n",
      "          -3.5560e-01,  3.0058e-02],\n",
      "         [ 1.5789e-01,  2.0096e-01, -1.3483e-01,  ..., -5.2093e-02,\n",
      "          -6.9464e-03, -8.9531e-02],\n",
      "         ...,\n",
      "         [-1.5437e-01,  3.3379e-01,  1.2433e-01,  ...,  2.4898e-02,\n",
      "          -5.9375e-03, -1.3339e-02],\n",
      "         [ 5.3858e-02,  3.3692e-01, -6.7198e-03,  ..., -1.6767e-01,\n",
      "           1.2856e-01,  9.7554e-03],\n",
      "         [ 1.7491e-01,  3.8467e-01,  7.4633e-02,  ..., -2.8190e-02,\n",
      "           6.8535e-02,  1.6387e-01]],\n",
      "\n",
      "        [[-4.5334e-01,  3.9357e-01, -2.4826e-01,  ..., -7.8468e-02,\n",
      "           1.9948e-01,  1.1272e-01],\n",
      "         [ 3.3446e-01,  4.8026e-05,  2.7089e-02,  ..., -2.6876e-01,\n",
      "           2.1251e-02,  2.9471e-01],\n",
      "         [ 1.8585e-01, -3.4736e-02, -4.8967e-02,  ..., -7.8985e-02,\n",
      "           2.1420e-02, -1.1045e-01],\n",
      "         ...,\n",
      "         [ 1.8069e-03,  1.6909e-01, -2.0712e-01,  ..., -1.2648e-01,\n",
      "          -2.9165e-02, -1.9992e-01],\n",
      "         [ 8.6461e-02,  1.4734e-01, -8.2163e-02,  ...,  1.1373e-01,\n",
      "          -5.5620e-02, -1.3148e-01],\n",
      "         [ 4.5301e-01,  1.0044e-01, -1.1060e-01,  ..., -1.5038e-02,\n",
      "          -6.5686e-02,  8.3277e-02]]], grad_fn=<SumBackward1>)\n",
      "Output original method:\n",
      "tensor([[[ 1.3082e-01,  1.6563e-01,  4.1653e-02,  ..., -2.2603e-01,\n",
      "          -7.3465e-02,  7.8630e-02],\n",
      "         [-1.3417e-01, -1.0778e-01, -1.8121e-02,  ..., -2.3720e-01,\n",
      "           6.4090e-02,  6.7970e-02],\n",
      "         [-1.5226e-01,  1.8696e-01, -8.2782e-02,  ...,  3.3045e-02,\n",
      "          -3.3825e-02,  7.5411e-02],\n",
      "         ...,\n",
      "         [ 2.0526e-01, -1.0766e-01,  1.1490e-01,  ..., -1.6139e-01,\n",
      "           1.9672e-01, -8.9715e-02],\n",
      "         [ 1.3444e-01, -1.1484e-01, -2.8529e-01,  ...,  4.9698e-02,\n",
      "           9.4008e-02,  2.1113e-01],\n",
      "         [-7.7669e-02,  5.6433e-03, -1.7898e-01,  ..., -7.0148e-02,\n",
      "           4.0989e-02, -2.4595e-01]],\n",
      "\n",
      "        [[-2.2096e-01,  1.5502e-01, -7.7533e-03,  ..., -1.0507e-01,\n",
      "           1.8487e-01, -1.7801e-01],\n",
      "         [-1.6388e-01, -2.0103e-01,  6.7127e-02,  ...,  2.8505e-02,\n",
      "          -3.3133e-01,  2.1417e-02],\n",
      "         [-4.4284e-01,  3.0237e-01,  1.4740e-01,  ...,  4.8788e-02,\n",
      "          -1.5588e-01,  3.9302e-01],\n",
      "         ...,\n",
      "         [-1.5761e-01,  2.4891e-01, -1.5799e-01,  ...,  7.6650e-02,\n",
      "          -3.9833e-01, -1.7371e-01],\n",
      "         [ 6.2172e-02, -3.9801e-02,  4.4738e-02,  ...,  1.6706e-02,\n",
      "          -3.9300e-01,  1.5341e-01],\n",
      "         [ 2.4012e-01,  4.6382e-01, -4.6103e-02,  ...,  1.3832e-01,\n",
      "          -1.3315e-01, -2.2044e-01]],\n",
      "\n",
      "        [[-5.5443e-02, -3.0804e-02,  2.1045e-02,  ..., -3.0459e-01,\n",
      "           1.8680e-01,  9.7737e-02],\n",
      "         [ 2.4402e-01,  2.9861e-01, -4.3307e-02,  ...,  2.1187e-01,\n",
      "          -3.5560e-01,  3.0057e-02],\n",
      "         [ 1.5789e-01,  2.0096e-01, -1.3483e-01,  ..., -5.2093e-02,\n",
      "          -6.9464e-03, -8.9531e-02],\n",
      "         ...,\n",
      "         [-1.5437e-01,  3.3379e-01,  1.2433e-01,  ...,  2.4898e-02,\n",
      "          -5.9376e-03, -1.3339e-02],\n",
      "         [ 5.3858e-02,  3.3692e-01, -6.7198e-03,  ..., -1.6767e-01,\n",
      "           1.2856e-01,  9.7554e-03],\n",
      "         [ 1.7491e-01,  3.8467e-01,  7.4633e-02,  ..., -2.8190e-02,\n",
      "           6.8536e-02,  1.6387e-01]],\n",
      "\n",
      "        [[-4.5334e-01,  3.9357e-01, -2.4826e-01,  ..., -7.8468e-02,\n",
      "           1.9948e-01,  1.1272e-01],\n",
      "         [ 3.3446e-01,  4.7922e-05,  2.7089e-02,  ..., -2.6876e-01,\n",
      "           2.1251e-02,  2.9471e-01],\n",
      "         [ 1.8585e-01, -3.4736e-02, -4.8967e-02,  ..., -7.8985e-02,\n",
      "           2.1420e-02, -1.1045e-01],\n",
      "         ...,\n",
      "         [ 1.8069e-03,  1.6909e-01, -2.0712e-01,  ..., -1.2648e-01,\n",
      "          -2.9164e-02, -1.9992e-01],\n",
      "         [ 8.6461e-02,  1.4734e-01, -8.2163e-02,  ...,  1.1373e-01,\n",
      "          -5.5620e-02, -1.3148e-01],\n",
      "         [ 4.5301e-01,  1.0044e-01, -1.1060e-01,  ..., -1.5038e-02,\n",
      "          -6.5686e-02,  8.3277e-02]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import os\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class SMoE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoE, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        gate_scores = self.gating_network(x)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Compute expert outputs for all experts in parallel\n",
    "        all_expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=2)  # (batch_size, seq_len, num_experts, input_dim)\n",
    "        \n",
    "        # Select top-k expert outputs\n",
    "        selected_expert_outputs = all_expert_outputs.gather(2, topk_indices.unsqueeze(-1).expand(-1, -1, -1, x.size(-1)))  # (batch_size, seq_len, 2, input_dim)\n",
    "        \n",
    "        # Calculate weights and apply them\n",
    "        weights = F.softmax(topk_scores, dim=-1).unsqueeze(-1)  # (batch_size, seq_len, 2, 1)\n",
    "        expert_outputs = (selected_expert_outputs * weights).sum(dim=2)  # (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        return expert_outputs, (topk_scores, topk_indices, gate_scores)\n",
    "\n",
    "class SMoEOriginal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoEOriginal, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        gate_scores = self.gating_network(x)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        expert_outputs = torch.zeros_like(x).to(device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_len):\n",
    "                indices = topk_indices[i, j]\n",
    "                weights = F.softmax(topk_scores[i, j], dim=-1)\n",
    "                output = sum(weights[k] * self.experts[indices[k].item()](x[i:i+1, j:j+1, :]) for k in range(2))\n",
    "                expert_outputs[i:i+1, j:j+1, :] = output\n",
    "        \n",
    "        return expert_outputs, (topk_scores, topk_indices, gate_scores)\n",
    "\n",
    "def test_models():\n",
    "    input_dim = 128\n",
    "    hidden_dim = 256\n",
    "    num_experts = 8\n",
    "    batch_size = 4\n",
    "    seq_len = 10\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    x = torch.randn(batch_size, seq_len, input_dim)\n",
    "\n",
    "    model_new = SMoE(input_dim, hidden_dim, num_experts)\n",
    "    model_original = SMoEOriginal(input_dim, hidden_dim, num_experts)\n",
    "\n",
    "    # Copy weights from model_original to model_new\n",
    "    model_new.gating_network.fc.weight.data.copy_(model_original.gating_network.fc.weight.data)\n",
    "    model_new.gating_network.fc.bias.data.copy_(model_original.gating_network.fc.bias.data)\n",
    "    for new_expert, original_expert in zip(model_new.experts, model_original.experts):\n",
    "        new_expert.fc1.weight.data.copy_(original_expert.fc1.weight.data)\n",
    "        new_expert.fc1.bias.data.copy_(original_expert.fc1.bias.data)\n",
    "        new_expert.fc2.weight.data.copy_(original_expert.fc2.weight.data)\n",
    "        new_expert.fc2.bias.data.copy_(original_expert.fc2.bias.data)\n",
    "\n",
    "    output_new, _ = model_new(x)\n",
    "    output_original, _ = model_original(x)\n",
    "\n",
    "    # Check if the outputs are close\n",
    "    if torch.allclose(output_new, output_original, atol=1e-6):\n",
    "        print(\"The outputs are the same for both methods.\")\n",
    "    else:\n",
    "        print(\"The outputs differ between the methods.\")\n",
    "\n",
    "    print(\"Output new method:\")\n",
    "    print(output_new)\n",
    "    print(\"Output original method:\")\n",
    "    print(output_original)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dddd3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 128])\n",
      "torch.Size([16, 10, 2]) torch.Size([16, 10, 2]) torch.Size([16, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class SMoE_MHA(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(SMoE_MHA, self).__init__()\n",
    "        # Input dim is here actually the embedding dimension.\n",
    "        self.h = 4\n",
    "        self.num_experts = num_experts\n",
    "        self.experts = nn.ModuleList([Expert(input_dim // self.h, hidden_dim) for _ in range(num_experts)])\n",
    "        self.gating_network = GatingNetwork(input_dim // self.h, num_experts)\n",
    "        self.pre_split_projection = nn.Linear(input_dim, input_dim)\n",
    "        self.align = nn.Linear(input_dim, input_dim)\n",
    "        self.embedding_dim = input_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Hardcode num_heads\n",
    "        num_heads = self.h\n",
    "        # x in shape (Batch, Time, Emb)\n",
    "        batch_size, seq_length, embedding_dim = x.size()\n",
    "        assert embedding_dim == self.embedding_dim, \"Embedding dimension mismatch\"\n",
    "\n",
    "        # Calculate new embedding dimension per head\n",
    "        head_dim = embedding_dim // num_heads\n",
    "        assert head_dim * num_heads == embedding_dim, \"Embedding dimension must be divisible by number of heads\"\n",
    "\n",
    "        # Step 0: Project\n",
    "        x = self.pre_split_projection(x)\n",
    "        \n",
    "        # Step 1: Reshape to [batch_size, num_heads, seq_length, head_dim]\n",
    "        x = x.view(batch_size, seq_length, num_heads, head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # Step 2: Flatten the last two dimensions for gating network input\n",
    "        x_flat = x.contiguous().view(batch_size * num_heads, seq_length, head_dim)\n",
    "        \n",
    "        # Step 3: Gating network\n",
    "        gate_scores = self.gating_network(x_flat)\n",
    "        topk_scores, topk_indices = torch.topk(gate_scores, 2, dim=-1)\n",
    "\n",
    "        # Step 4: Compute outputs for all experts\n",
    "        all_expert_outputs = torch.stack([expert(x_flat) for expert in self.experts], dim=2)  # (batch_size*num_heads, seq_length, num_experts, head_dim)\n",
    "        \n",
    "        # Step 5: Select top-k expert outputs\n",
    "        selected_expert_outputs = all_expert_outputs.gather(2, topk_indices.unsqueeze(-1).expand(-1, -1, -1, head_dim))  # (batch_size*num_heads, seq_length, 2, head_dim)\n",
    "        \n",
    "        # Step 6: Calculate weights and apply them\n",
    "        weights = F.softmax(topk_scores, dim=-1).unsqueeze(-1)  # (batch_size*num_heads, seq_length, 2, 1)\n",
    "        expert_outputs = (selected_expert_outputs * weights).sum(dim=2)  # (batch_size*num_heads, seq_length, head_dim)\n",
    "        \n",
    "        # Step 7: Apply residual connection\n",
    "        x_flat = x_flat + expert_outputs\n",
    "\n",
    "        # Step 8: Reshape back to original dimensions\n",
    "        x = x_flat.view(batch_size, num_heads, seq_length, head_dim).permute(0, 2, 1, 3)\n",
    "        x = x.contiguous().view(batch_size, seq_length, embedding_dim)\n",
    "        \n",
    "        # Step 9: Apply FFN to align mis-paired values\n",
    "        x = self.align(x)\n",
    "        \n",
    "        return x, (topk_scores, topk_indices, gate_scores)\n",
    "\n",
    "# Example usage\n",
    "input_dim = 128\n",
    "hidden_dim = 256\n",
    "num_experts = 8\n",
    "batch_size = 4\n",
    "seq_length = 10\n",
    "\n",
    "model = SMoE_MHA(input_dim, hidden_dim, num_experts)\n",
    "x = torch.randn(batch_size, seq_length, input_dim)\n",
    "output, (topk_scores, topk_indices, gate_scores) = model(x)\n",
    "\n",
    "print(output.shape)\n",
    "print(topk_scores.shape, topk_indices.shape, gate_scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63cd3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand([3,2,1,4])\n",
    "b = torch.rand([3,2,1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e73e06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8692b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [a,b]\n",
    "cc = torch.cat(c,dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4f46808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57992ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
